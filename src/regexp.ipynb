{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "codes = pd.read_csv(\"../processed_data/code_top300.csv\")\n",
    "# codes.iloc[:,0] = codes.index.values\n",
    "df = pd.DataFrame(columns = ['text', 'tokens', 'annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "identifier = r'[a-zA-Z_][\\d\\w_]*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "keywords = r'''break|default|func|interface|select|case|defer\n",
    "                |go|map|struct|chan|else|goto|package|switch\n",
    "                |const|fallthrough|if|range|type|continue|for|import|return|var'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# operators and punctuation\n",
    "operators = r'[\\+\\-\\*\\,;\\$><!:\\.\\|&\\^=\\(\\)\\[\\]\\{\\}]+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "decimal_literal = r'\\d+i?'           \n",
    "octal_literal = r'0[1-7]*'\n",
    "hex_literal = r'0[xX][a-fA-F]+'\n",
    "floating_literal = r''' \\d+\\.\\d*(?:[eE][+-]\\d+)?i?     \n",
    "                | \\d+[eE][+-]\\d+i?               \n",
    "                | \\.\\d+(?:[eE][+-]\\d+)?i?        \n",
    "                '''\n",
    "string_literal = r'''\\\"\\s*.*\\n?\\\"'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments = r'//.*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patterns =  keywords + '|' + identifier + '|' + operators + '|' \\\n",
    "        + decimal_literal + '|' + octal_literal + '|' + hex_literal + '|' \\\n",
    "        + floating_literal + '|' + string_literal + '|' + comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# annotations is used to store all the 100 posts\n",
    "# each element in this array should be one particular post\n",
    "annotations = []\n",
    "for index, code in enumerate(codes['Code'][:100]):\n",
    "    # post is used to store line by line info\n",
    "    post = []\n",
    "    # dic is used to store the overall info for one post\n",
    "    dic = {'text' : code, 'tokens' : [], 'anns' : []}\n",
    "    \n",
    "    code_lines = list(filter(None, code.split('\\n')))\n",
    "    for line in code_lines:\n",
    "        # store line info then append to 'post' array\n",
    "        line_info = [line]\n",
    "        tokens = tokenizer.tokenize(line)\n",
    "        line_info.append(tokens)\n",
    "        dic['tokens'] += (tokens)\n",
    "        # start annotation\n",
    "        ann = []\n",
    "        for t in tokens:\n",
    "            if re.match(comments, t):\n",
    "                ann.append('COMMENT')\n",
    "                t = t.replace('//', '')\n",
    "                # annotate comments as natural language\n",
    "                tags = nltk.pos_tag(nltk.word_tokenize(t))\n",
    "                ann += [tags[i][1] for i in range(len(tags))]\n",
    "            elif re.match(keywords, t):\n",
    "                ann.append('KEYWORD')\n",
    "            elif re.match(identifier, t):\n",
    "                ann.append('IDENTIFIER')\n",
    "            elif re.match(operators, t):\n",
    "                ann.append('OPERATOR')\n",
    "            elif re.match(decimal_literal, t):\n",
    "                ann.append('DECIMAL_LITERAL')\n",
    "            elif re.match(octal_literal, t):\n",
    "                ann.append('OCTAL_LITERAL')\n",
    "            elif re.match(hex_literal, t):\n",
    "                ann.append('HEX_LITERAL')\n",
    "            elif re.match(string_literal, t):\n",
    "                ann.append('STRING_LITERAL')\n",
    "            elif re.match(floating_literal, t):\n",
    "                ann.append('FLOATING_LITERAL')\n",
    "            else:\n",
    "                ann.append('UNDEFINED')\n",
    "        line_info.append(ann)\n",
    "        dic['anns'] += (ann)\n",
    "        post.append(line_info)\n",
    "        \n",
    "    # df for each post, do line by line annotation\n",
    "    post_df = pd.DataFrame(post, columns = ['text', 'token', 'annotation'])\n",
    "    post_df.to_csv('../processed_data/annotations/'+str(index)+'.csv')\n",
    "    \n",
    "    annotations.append(dic.values())\n",
    "# df for all posts\n",
    "results = pd.DataFrame(annotations, columns = ['text', 'tokens', 'annotations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results['post_id'] = codes['PostId']\n",
    "results.to_csv('../processed_data/ann_100_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
